{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pycocotools\n",
        "\n",
        "import os, random, zipfile, json\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "DATASET_DIR = \"mini_coco_sample\"\n",
        "TOTAL_IMAGES = 50\n",
        "COCO_URL_IMAGES = \"http://images.cocodataset.org/val2017/\"\n",
        "COCO_URL_ANN = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
        "\n",
        "if not os.path.exists(f\"{DATASET_DIR}/images\"):\n",
        "    if not os.path.exists(\"annotations\"):\n",
        "        !wget -q {COCO_URL_ANN}\n",
        "        !unzip -q annotations_trainval2017.zip\n",
        "    coco = COCO(\"annotations/instances_val2017.json\")\n",
        "    img_ids = coco.getImgIds()\n",
        "    selected_ids = random.sample(img_ids, TOTAL_IMAGES)\n",
        "\n",
        "    os.makedirs(f\"{DATASET_DIR}/images\", exist_ok=True)\n",
        "    os.makedirs(f\"{DATASET_DIR}/annotations\", exist_ok=True)\n",
        "\n",
        "    # download images\n",
        "    for img_id in selected_ids:\n",
        "        info = coco.loadImgs(img_id)[0]\n",
        "        url = COCO_URL_IMAGES + info[\"file_name\"]\n",
        "        !wget -q -P {DATASET_DIR}/images {url}\n",
        "\n",
        "    # subset annotations\n",
        "    ann_ids = coco.getAnnIds(imgIds=selected_ids)\n",
        "    anns = coco.loadAnns(ann_ids)\n",
        "    mini_coco = {\n",
        "        \"images\": [coco.loadImgs(i)[0] for i in selected_ids],\n",
        "        \"annotations\": anns,\n",
        "        \"categories\": coco.loadCats(coco.getCatIds())\n",
        "    }\n",
        "    with open(f\"{DATASET_DIR}/annotations/instances.json\",\"w\") as f:\n",
        "        json.dump(mini_coco,f,indent=2)\n",
        "\n",
        "print(\"✅ mini_coco_sample is ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w5SqlTGDG1A",
        "outputId": "245c981a-358e-47f3-dd15-450995433072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.51s)\n",
            "creating index...\n",
            "index created!\n",
            "✅ mini_coco_sample is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, random, shutil\n",
        "\n",
        "BASE = \"mini_coco_sample\"\n",
        "random.seed(42)\n",
        "\n",
        "# Load subset JSON\n",
        "with open(f\"{BASE}/annotations/instances.json\",\"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Image IDs present in subset\n",
        "image_ids = [img[\"id\"] for img in data[\"images\"]]\n",
        "random.shuffle(image_ids)\n",
        "split = int(0.8 * len(image_ids))\n",
        "train_ids, val_ids = set(image_ids[:split]), set(image_ids[split:])\n",
        "\n",
        "def build_split(ids_set):\n",
        "    images = [im for im in data[\"images\"] if im[\"id\"] in ids_set]\n",
        "    anns = [an for an in data[\"annotations\"] if an[\"image_id\"] in ids_set]\n",
        "    return {\"images\": images, \"annotations\": anns, \"categories\": data[\"categories\"]}\n",
        "\n",
        "splits = {\"train\": build_split(train_ids), \"val\": build_split(val_ids)}\n",
        "\n",
        "# Make split dirs and copy images\n",
        "for sp in [\"train\",\"val\"]:\n",
        "    os.makedirs(f\"{BASE}/{sp}/images\", exist_ok=True)\n",
        "    os.makedirs(f\"{BASE}/{sp}/annotations\", exist_ok=True)\n",
        "    # save JSON\n",
        "    with open(f\"{BASE}/{sp}/annotations/instances.json\",\"w\") as f:\n",
        "        json.dump(splits[sp], f, indent=2)\n",
        "    # copy images\n",
        "    present = {im[\"file_name\"] for im in splits[sp][\"images\"]}\n",
        "    for fname in present:\n",
        "        src = f\"{BASE}/images/{fname}\"\n",
        "        dst = f\"{BASE}/{sp}/images/{fname}\"\n",
        "        if not os.path.exists(dst):\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "print(\"✅ Train/Val split created.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDAnJblvDJ91",
        "outputId": "5306f5f3-0f7d-4648-f166-4df64b623881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train/Val split created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pycocotools\n",
        "\n",
        "import torch, torchvision, json, os, numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBdMilguDNIw",
        "outputId": "26fb3c48-4d79-4df5-f561-81be033b46fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "class COCOSubset(Dataset):\n",
        "    def __init__(self, images_dir, ann_json):\n",
        "        self.images_dir = images_dir\n",
        "        with open(ann_json,\"r\") as f:\n",
        "            d = json.load(f)\n",
        "        self.categories = d[\"categories\"]\n",
        "        # image_id -> file_name, size\n",
        "        self.images = {im[\"id\"]: im for im in d[\"images\"]}\n",
        "        # group annotations per image_id\n",
        "        ann_per_img = collections.defaultdict(list)\n",
        "        for an in d[\"annotations\"]:\n",
        "            # filter invalid boxes (area <=0, or w/h<=0)\n",
        "            x,y,w,h = an[\"bbox\"]\n",
        "            if w <= 0 or h <= 0:\n",
        "                continue\n",
        "            ann_per_img[an[\"image_id\"]].append(an)\n",
        "        self.ann_per_img = ann_per_img\n",
        "        self.ids = list(self.images.keys())\n",
        "\n",
        "    def __len__(self): return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "        info = self.images[img_id]\n",
        "        path = os.path.join(self.images_dir, info[\"file_name\"])\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "        anns = self.ann_per_img.get(img_id, [])\n",
        "        boxes, labels, areas, iscrowd = [], [], [], []\n",
        "        for an in anns:\n",
        "            x,y,w,h = an[\"bbox\"]\n",
        "            boxes.append([x, y, x+w, y+h])\n",
        "            labels.append(an[\"category_id\"])        # COCO IDs (1..90), OK for pretrained head\n",
        "            areas.append(an.get(\"area\", w*h))\n",
        "            iscrowd.append(an.get(\"iscrowd\", 0))\n",
        "\n",
        "        if len(boxes)==0: # handle images with zero annotations gracefully\n",
        "            boxes = np.zeros((0,4), dtype=np.float32)\n",
        "            labels = np.zeros((0,), dtype=np.int64)\n",
        "            areas = np.zeros((0,), dtype=np.float32)\n",
        "            iscrowd = np.zeros((0,), dtype=np.int64)\n",
        "        else:\n",
        "            boxes = np.array(boxes, dtype=np.float32)\n",
        "            labels = np.array(labels, dtype=np.int64)\n",
        "            areas = np.array(areas, dtype=np.float32)\n",
        "            iscrowd = np.array(iscrowd, dtype=np.int64)\n",
        "\n",
        "        img_t = to_tensor(img)  # [0,1] float32\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": torch.as_tensor(boxes, dtype=torch.float32),\n",
        "            \"labels\": torch.as_tensor(labels, dtype=torch.int64),\n",
        "            \"image_id\": torch.tensor([img_id]),\n",
        "            \"area\": torch.as_tensor(areas, dtype=torch.float32),\n",
        "            \"iscrowd\": torch.as_tensor(iscrowd, dtype=torch.int64),\n",
        "        }\n",
        "        return img_t, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "train_ds = COCOSubset(\"mini_coco_sample/train/images\", \"mini_coco_sample/train/annotations/instances.json\")\n",
        "val_ds   = COCOSubset(\"mini_coco_sample/val/images\",   \"mini_coco_sample/val/annotations/instances.json\")\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
        "val_dl   = DataLoader(val_ds,   batch_size=2, shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
        "\n",
        "len(train_ds), len(val_ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJZE2n9HDT2Z",
        "outputId": "ce8c5fe0-7f4e-457d-9b7d-a7ed81981387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "# Pretrained weights\n",
        "model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")  # 91-class COCO head\n",
        "model.to(DEVICE)\n",
        "\n",
        "# Optimizer & LR scheduler\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.002, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "\n",
        "print(\"✅ Model ready on\", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCrHS1qjDXQL",
        "outputId": "d159f62f-3d91-46dd-93bb-16ac7fa445b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model ready on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import torchvision\n",
        "\n",
        "os.makedirs(\"predictions\", exist_ok=True)\n",
        "\n",
        "# Try to load a default font for labels\n",
        "try:\n",
        "    font = ImageFont.truetype(\"DejaVuSans.ttf\", 16)\n",
        "except:\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "model.eval()\n",
        "score_thresh = 0.5\n",
        "\n",
        "# COCO category id -> name\n",
        "with open(\"mini_coco_sample/train/annotations/instances.json\",\"r\") as f:\n",
        "    cats = {c[\"id\"]: c[\"name\"] for c in json.load(f)[\"categories\"]}\n",
        "\n",
        "def draw_predictions(img_pil, boxes, labels, scores):\n",
        "    draw = ImageDraw.Draw(img_pil)\n",
        "    for box, lab, sc in zip(boxes, labels, scores):\n",
        "        if sc < score_thresh:\n",
        "            continue\n",
        "        x1,y1,x2,y2 = box\n",
        "        draw.rectangle([x1,y1,x2,y2], outline=(0,255,0), width=3)\n",
        "        text = f\"{cats.get(int(lab), lab)} {sc:.2f}\"\n",
        "        ts = draw.textbbox((0,0), text, font=font)\n",
        "        tw, th = ts[2]-ts[0], ts[3]-ts[1]\n",
        "        draw.rectangle([x1, y1-th-4, x1+tw+4, y1], fill=(0,255,0))\n",
        "        draw.text((x1+2, y1-th-2), text, fill=(0,0,0), font=font)\n",
        "    return img_pil\n",
        "\n",
        "# Run on all val images\n",
        "val_images = [im[\"file_name\"] for im in json.load(open(\"mini_coco_sample/val/annotations/instances.json\"))[\"images\"]]\n",
        "for fname in val_images:\n",
        "    path = os.path.join(\"mini_coco_sample/val/images\", fname)\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    img_t = to_tensor(img).to(DEVICE).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        out = model(img_t)[0]\n",
        "    boxes = out[\"boxes\"].cpu().numpy()\n",
        "    labels = out[\"labels\"].cpu().numpy()\n",
        "    scores = out[\"scores\"].cpu().numpy()\n",
        "    vis = draw_predictions(img.copy(), boxes, labels, scores)\n",
        "    vis.save(os.path.join(\"predictions\", fname))\n",
        "\n",
        "print(\"✅ Saved visualized predictions in /predictions\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHe_OJjqNofM",
        "outputId": "696e84ca-0357-4508-d308-c422361240e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved visualized predictions in /predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile, os\n",
        "from google.colab import files\n",
        "\n",
        "zip_name = \"predictions.zip\"\n",
        "with zipfile.ZipFile(zip_name, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for f in os.listdir(\"predictions\"):\n",
        "        zf.write(os.path.join(\"predictions\", f), f)\n",
        "\n",
        "print(f\"✅ {zip_name} ready.\")\n",
        "files.download(zip_name)\n"
      ],
      "metadata": {
        "id": "pRnm4esOOa6n",
        "outputId": "09ffac8b-a31d-4550-cd72-0f96734d38b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ predictions.zip ready.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_04dca1f2-e999-41c4-826a-3fc996ea0375\", \"predictions.zip\", 661656)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"fasterrcnn_resnet50fpn_subset.pth\")\n",
        "from google.colab import files\n",
        "files.download(\"fasterrcnn_resnet50fpn_subset.pth\")\n"
      ],
      "metadata": {
        "id": "AjIf2CxWOe3_",
        "outputId": "18bdeae5-6c0f-4255-dcdc-305b45733f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_da3efd71-2d65-4d5e-bdd3-5c0e88c4f0bf\", \"fasterrcnn_resnet50fpn_subset.pth\", 167558991)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}